<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="AI & Machine Learning Mastery Plan ‚Äî Revision 4 (LLM-Focused). A comprehensive 12-month learning roadmap for mastering LLM systems from fundamentals to production.">
  <meta name="author" content="DovJNash">
  <title>AI & Machine Learning Mastery Plan ‚Äî Revision 4 (LLM-Focused)</title>
  
  <!-- Google Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
  
  <!-- Stylesheet -->
  <link rel="stylesheet" href="/assets/css/main.css">
</head>
<body>
  <!-- Skip to Content Link -->
  <a href="#main-content" class="skip-to-content">Skip to content</a>
  
  <!-- Header with Sticky Navigation -->
  <header class="header" role="banner">
    <div class="header-container">
      <h1 class="site-title">AI & ML Mastery Plan</h1>
      <button class="nav-toggle" aria-label="Open navigation menu" aria-expanded="false">‚ò∞</button>
      <nav class="main-nav" role="navigation" aria-label="Main navigation">
        <ul>
          <li><a href="#direction">Direction</a></li>
          <li><a href="#outcomes">Outcomes</a></li>
          <li><a href="#tooling">Tooling</a></li>
          <li><a href="#timeline">Timeline</a></li>
          <li><a href="#weekly-plan">Weekly Plan</a></li>
          <li><a href="#daily-breakdown">Daily Breakdown</a></li>
          <li><a href="#israeli-context">Israeli Context</a></li>
          <li><a href="#gpu-strategy">GPU Strategy</a></li>
          <li><a href="#research">Research</a></li>
          <li><a href="#community">Community</a></li>
          <li><a href="#success-criteria">Success</a></li>
          <li><a href="#failure-recovery">Recovery</a></li>
          <li><a href="#mlops">MLOps</a></li>
          <li><a href="#changes">Changes</a></li>
          <li><a href="#repo-structure">Repo</a></li>
          <li><a href="#next-actions">Next Actions</a></li>
          <li><a href="#mindset">Mindset</a></li>
        </ul>
      </nav>
    </div>
  </header>
  
  <!-- Hero Section -->
  <section class="hero" role="banner">
    <div class="hero-container">
      <h1>AI & Machine Learning Mastery Plan</h1>
      <p class="lead">Revision 4 (LLM-Focused, With All Notes Fixed)</p>
      <div class="hero-meta">
        <span><strong>Student:</strong> DovJNash (9th grade, Israel)</span>
        <span><strong>Date:</strong> 2025-11-08</span>
        <span><strong>Duration:</strong> 12 months (52 weeks)</span>
      </div>
    </div>
  </section>
  
  <!-- Main Content -->
  <main id="main-content" class="main-content" role="main">
    
    <!-- 1. Author's Direction Note -->
    <section id="direction" class="content-section">
      <div class="section-header">
        <h2>1. Author's Direction Note</h2>
        <button class="anchor-link" aria-label="Copy link to this section" title="Copy link">#</button>
      </div>
      <div class="callout callout-info">
        <div class="callout-title">üéØ Supersedes Prior Revisions</div>
        <p><strong>Robotics/control are out of scope going forward.</strong> All energy is on LLM systems end-to-end:</p>
        <ul>
          <li>Tokenizer ‚Üí embedding ‚Üí attention/Transformer</li>
          <li>Training loops ‚Üí scaling laws ‚Üí PEFT (LoRA/QLoRA)</li>
          <li>Inference optimization ‚Üí serving ‚Üí evaluation & safety</li>
          <li>Portfolio development and deployment</li>
        </ul>
      </div>
    </section>
    
    <!-- 2. Outcomes by Month 12 -->
    <section id="outcomes" class="content-section">
      <div class="section-header">
        <h2>2. Outcomes by Month 12</h2>
        <button class="anchor-link" aria-label="Copy link to this section" title="Copy link">#</button>
      </div>
      <div class="card-grid">
        <div class="card">
          <h3 class="card-title">üìê Foundations</h3>
          <ol>
            <li>Strong, applied math foundations (linear algebra, calculus for optimization, probability/statistics)</li>
            <li>Classical ML literacy and evaluation (sklearn baselines, metrics, learning curves)</li>
          </ol>
        </div>
        <div class="card">
          <h3 class="card-title">üß† Deep Learning</h3>
          <ol start="3">
            <li>Deep learning engineering (PyTorch, training loops, stability, mixed precision, logging)</li>
            <li>Transformer internals mastery; implement GPT-style model from scratch with unit tests</li>
          </ol>
        </div>
        <div class="card">
          <h3 class="card-title">üöÄ LLM Systems</h3>
          <ol start="5">
            <li>Pretrain small models (1‚Äì30M params) on curated corpora; run small-scale scaling laws</li>
            <li>Efficient fine-tuning (LoRA/QLoRA), quantization and KV-cache for fast inference</li>
          </ol>
        </div>
        <div class="card">
          <h3 class="card-title">üéØ Production</h3>
          <ol start="7">
            <li>Evaluation harness (perplexity + human rubric), safety filters, latency and cost tracking</li>
            <li>Production MVP: FastAPI, Docker, HTTPS domain, Sentry monitoring, CI</li>
            <li>Portfolio with documented repos, bilingual blog posts (Hebrew + English), and public demos</li>
          </ol>
        </div>
      </div>
    </section>
    
    <!-- 3. Tooling & Benefits -->
    <section id="tooling" class="content-section">
      <div class="section-header">
        <h2>3. Tooling & Benefits (with Usage Plan)</h2>
        <button class="anchor-link" aria-label="Copy link to this section" title="Copy link">#</button>
      </div>
      <table>
        <thead>
          <tr>
            <th>Category</th>
            <th>Tool/Service</th>
            <th>Usage Plan</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>IDE + Git</td>
            <td>VS Code + Copilot Pro + GitLens</td>
            <td>Daily development environment</td>
          </tr>
          <tr>
            <td>Notebooks</td>
            <td>Deepnote Team plan</td>
            <td>Collaboration and experimentation</td>
          </tr>
          <tr>
            <td>Secrets</td>
            <td>1Password</td>
            <td>Store all tokens/keys securely</td>
          </tr>
          <tr>
            <td>Docs/PM</td>
            <td>Notion Education + AI</td>
            <td>Logs, paper summaries, planning</td>
          </tr>
          <tr>
            <td>Compute</td>
            <td>Kaggle (free T4)</td>
            <td>Default for prototypes/CIFAR and scaling runs</td>
          </tr>
          <tr>
            <td>Compute</td>
            <td>Colab Pro</td>
            <td>ONE month (~$10) during Weeks 23‚Äì33 for pretraining/scaling</td>
          </tr>
          <tr>
            <td>Compute</td>
            <td>Azure $100 credit</td>
            <td>Reserve $40‚Äì$60 for QLoRA (Weeks 37‚Äì40); ~$40 emergency buffer</td>
          </tr>
          <tr>
            <td>Hosting</td>
            <td>DigitalOcean $200 credit</td>
            <td>API/static site hosting</td>
          </tr>
          <tr>
            <td>Data/DB</td>
            <td>MongoDB Atlas $50</td>
            <td>Experiment tracking (metrics, prompts/responses, eval scores)</td>
          </tr>
          <tr>
            <td>Courses</td>
            <td>DataCamp</td>
            <td>Weeks 1‚Äì11: foundations and classical ML</td>
          </tr>
          <tr>
            <td>Courses</td>
            <td>Educative</td>
            <td>Weeks 11‚Äì17: when stuck on deep learning concepts</td>
          </tr>
          <tr>
            <td>Courses</td>
            <td>FrontendMasters</td>
            <td>Weeks 34‚Äì36: UI/streaming for MVP</td>
          </tr>
        </tbody>
      </table>
    </section>
    
    <!-- 4. Macro Timeline -->
    <section id="timeline" class="content-section">
      <div class="section-header">
        <h2>4. Macro Timeline (12 months) with Buffers & Reviews</h2>
        <button class="anchor-link" aria-label="Copy link to this section" title="Copy link">#</button>
      </div>
      <div class="timeline">
        <div class="timeline-item">
          <h4>Weeks 1‚Äì6: Foundations</h4>
          <p>Math + Python-for-Data; NumPy, vectors, probability, gradients</p>
          <p><strong>Review at Week 6</strong></p>
        </div>
        <div class="timeline-item">
          <h4>Weeks 7‚Äì10: Classical ML</h4>
          <p>Sklearn, metrics, cross-validation, learning curves</p>
          <p><strong>Review at Week 10</strong></p>
        </div>
        <div class="timeline-item">
          <h4>Weeks 11‚Äì17: Deep Learning Core</h4>
          <p>PyTorch MLP/CNN, stability, activation/grad viz, CIFAR-10</p>
          <p><strong>Review at Week 17</strong></p>
        </div>
        <div class="timeline-item">
          <h4>Weeks 18‚Äì22: NLP & Transformer Fundamentals</h4>
          <p>Attention, MHA, positional encoding, Pre-LN blocks, papers (AIAIN, BERT)</p>
          <p><strong>Review at Week 22</strong></p>
        </div>
        <div class="timeline-item">
          <h4>Weeks 23‚Äì28: GPT from Scratch & Char Pretraining</h4>
          <p>Training loops, grad accumulation, mixed precision, sampling strategies</p>
          <p><strong>Review at Week 28</strong></p>
        </div>
        <div class="timeline-item">
          <h4>Weeks 29‚Äì33: Tokenizer (BPE 16k) + Data Curation + Scaling Laws Lab</h4>
          <p>BPE training, data normalization/dedup, scaling experiments (1M‚Äì30M)</p>
          <p><strong>Review at Week 33</strong></p>
        </div>
        <div class="timeline-item">
          <h4>Weeks 34‚Äì36: Serving MVP + Ethics/Safety</h4>
          <p>FastAPI, Docker, HTTPS, Sentry, safety filters, minimal UI</p>
          <p><strong>Review at Week 36</strong></p>
        </div>
        <div class="timeline-item">
          <h4>Weeks 37‚Äì40: PEFT/QLoRA + Inference Optimization</h4>
          <p>LoRA/QLoRA fine-tuning (3B‚Äì7B), quantization (8/4-bit), KV-cache</p>
          <p><strong>Review at Week 40</strong></p>
        </div>
        <div class="timeline-item">
          <h4>Weeks 41‚Äì44: MLOps (Essential Hardening)</h4>
          <p>Pytest, black, CI, YAML configs, JSONL logging, cleanup scripts</p>
          <p><strong>Review at Week 44</strong></p>
        </div>
        <div class="timeline-item">
          <h4>Weeks 45‚Äì48: Capstone Build/Iterate</h4>
          <p>Choose ONE: Math Study Assistant OR Hebrew‚ÄìEnglish Code Assistant</p>
          <p><strong>Review at Week 48</strong></p>
        </div>
        <div class="timeline-item">
          <h4>Weeks 49‚Äì52: Portfolio & Final Polish</h4>
          <p>Bilingual blogs, architecture diagrams, documentation</p>
          <p><strong>Final assessment</strong></p>
        </div>
      </div>
      <div class="callout callout-warning">
        <div class="callout-title">‚è∏Ô∏è Buffer Weeks</div>
        <p><strong>Light/catch-up weeks:</strong> Weeks 7, 18, 26‚Äì28 (Bagrut prep), 41</p>
      </div>
    </section>
    
    <!-- 5. Detailed Weekly Plan -->
    <section id="weekly-plan" class="content-section">
      <div class="section-header">
        <h2>5. Detailed Weekly Plan (Condensed)</h2>
        <button class="anchor-link" aria-label="Copy link to this section" title="Copy link">#</button>
      </div>
      
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">Weeks 1‚Äì6: Math + Python-for-Data</h3>
        </div>
        <ul>
          <li>DataCamp: NumPy, Intermediate Python, Visualization, Statistics</li>
          <li>Notebooks: vectors‚Üíeigenvalues, probability simulations, manual gradients</li>
          <li><strong>Week 6 mandatory review:</strong>
            <ul>
              <li>Quiz ‚â•16/20</li>
              <li>Linear regression from scratch with R¬≤&gt;0.90</li>
              <li>PCA from scratch</li>
              <li>foundations_summary.md ‚â•5 pages</li>
            </ul>
          </li>
          <li>Extend 2‚Äì4 weeks if needed</li>
        </ul>
      </div>
      
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">Week 7: Buffer & Structure</h3>
        </div>
        <ul>
          <li>Setup: pytest + black</li>
          <li>Deepnote migration</li>
          <li>Start weekly logs</li>
        </ul>
      </div>
      
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">Weeks 8‚Äì10: Classical ML</h3>
        </div>
        <ul>
          <li>Sklearn: classifiers, regressors, pipelines</li>
          <li>Metrics: accuracy, precision, recall, F1, ROC-AUC</li>
          <li>Cross-validation and learning curves</li>
          <li>Deliverable: <code>classical_ml_report.md</code></li>
        </ul>
      </div>
      
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">Weeks 11‚Äì17: Deep Learning Core</h3>
        </div>
        <ul>
          <li>PyTorch: MLP/CNN architectures</li>
          <li>Stability tactics: learning rate scheduling, gradient clipping, normalization</li>
          <li>Activation/gradient visualization</li>
          <li>Kaggle GPU sprint for CIFAR-10</li>
          <li>Deliverable: <code>deep_learning_health_check.md</code></li>
        </ul>
      </div>
      
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">Week 18: Buffer & NLP Warmup</h3>
        </div>
        <ul>
          <li>Tiny character dataset</li>
          <li>Optional: tiny RNN experiment</li>
        </ul>
      </div>
      
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">Weeks 19‚Äì22: Transformer Fundamentals</h3>
        </div>
        <ul>
          <li>Attention mechanism, Multi-Head Attention (MHA)</li>
          <li>Positional encoding, Pre-LN blocks</li>
          <li>Unit tests for attention</li>
          <li>Attention heatmaps visualization</li>
          <li>Papers: "Attention Is All You Need" (AIAIN) + BERT</li>
          <li>Deliverable: <code>transformer_fundamentals_summary.md</code></li>
        </ul>
      </div>
      
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">Weeks 23‚Äì28: GPT from Scratch (Char)</h3>
        </div>
        <ul>
          <li>Full training loop with gradient accumulation and mixed precision</li>
          <li>Sampling strategies: greedy, temperature, top-k, top-p</li>
          <li>Repetition penalty implementation</li>
          <li>Colab Pro month for 5‚Äì20M parameter models</li>
          <li>Papers: GPT-2, GPT-3</li>
          <li>Deliverable: <code>scaling_report_v1.md</code></li>
        </ul>
      </div>
      
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">Weeks 29‚Äì33: BPE Tokenizer + Data + Scaling Laws</h3>
        </div>
        <ul>
          <li>Train BPE tokenizer with 16k vocab</li>
          <li>Data curation: normalize, deduplicate, filter</li>
          <li>Create <code>dataset_report.md</code></li>
          <li>Small-scale scaling laws: 1M/3M/10M/20M/30M parameter models</li>
          <li>Track compute vs loss curves</li>
          <li>Paper: Chinchilla</li>
          <li>Deliverable: <code>tokenizer_data_scaling_summary.md</code></li>
        </ul>
      </div>
      
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">Weeks 34‚Äì36: Ethics/Safety + MVP Serving</h3>
        </div>
        <ul>
          <li>Create <code>safety.md</code> and <code>filtering.py</code></li>
          <li>Red-team with 100 prompts</li>
          <li>MVP serving: FastAPI, Docker, DigitalOcean, HTTPS, Sentry</li>
          <li>Minimal UI (FrontendMasters guidance)</li>
          <li>Deliverable: <code>deployment_mvp_report.md</code></li>
        </ul>
      </div>
      
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">Weeks 37‚Äì40: PEFT/QLoRA + Inference Optimization</h3>
        </div>
        <ul>
          <li>Fine-tune 3B‚Äì7B models with LoRA/QLoRA</li>
          <li>Quantization: 8-bit and 4-bit</li>
          <li>KV-cache implementation</li>
          <li>Azure budget: $40‚Äì$60 reserved</li>
          <li>Papers: LoRA, FlashAttention</li>
          <li>Deliverable: <code>peft_inference_summary.md</code></li>
        </ul>
      </div>
      
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">Week 41: Buffer</h3>
        </div>
        <ul>
          <li>Cleanup and refactoring</li>
          <li>Tests for tokenizer/sampling</li>
        </ul>
      </div>
      
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">Weeks 42‚Äì44: MLOps Essentials</h3>
        </div>
        <ul>
          <li>Pytest, black, GitHub Actions CI</li>
          <li>Simple YAML configs</li>
          <li>Cleanup scripts</li>
          <li>JSONL logging</li>
          <li>Optional: torch.profiler / torch.compile</li>
        </ul>
      </div>
      
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">Weeks 45‚Äì48: Capstone (Choose ONE)</h3>
        </div>
        <p><strong>Option A: Math Study Assistant</strong></p>
        <ul>
          <li>10‚Äì20M parameter model</li>
          <li>500‚Äì1000 Q&A pairs</li>
          <li>Evaluate on 100 problems</li>
          <li>Success: ‚â•60% correct, explanations ‚â•3.5/5</li>
        </ul>
        <p><strong>Option B: Hebrew‚ÄìEnglish Code Assistant</strong></p>
        <ul>
          <li>15‚Äì25M parameter model</li>
          <li>Bilingual coding tasks</li>
          <li>Success: ‚â•50% tasks pass, explanations ‚â•3.5/5</li>
        </ul>
      </div>
      
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">Weeks 49‚Äì52: Portfolio & Polish</h3>
        </div>
        <ul>
          <li>Write bilingual blogs (Hebrew + English):
            <ul>
              <li>Scaling lessons learned</li>
              <li>BPE tokenizer pitfalls</li>
              <li>MVP shipping process</li>
            </ul>
          </li>
          <li>Create architecture diagrams</li>
          <li>Final deliverable: <code>master_summary.txt</code></li>
        </ul>
      </div>
    </section>
    </section>
    
    <!-- 5.5 Daily Breakdown (14 Program Phases) -->
    <section id="daily-breakdown" class="content-section">
      <div class="section-header">
        <h2>5.5 Daily Breakdown (14 Program Phases)</h2>
        <button class="anchor-link" aria-label="Copy link to this section" title="Copy link">#</button>
      </div>
      
      <div class="callout callout-info">
        <div class="callout-title">üìÖ Daily Task Breakdown</div>
        <p>This section provides detailed daily breakdowns for each program phase, showing specific tasks, time allocations, and deliverables for every day of the 52-week plan.</p>
      </div>

      <!-- Phase 1: Weeks 1-6 Foundations -->
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">Phase 1: Weeks 1-6 ‚Äî Math + Python-for-Data Foundations</h3>
        </div>
        <table>
          <thead>
            <tr>
              <th>Day</th>
              <th>Week</th>
              <th>Tasks</th>
              <th>Time (hrs)</th>
              <th>Deliverables</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>1-5</td>
              <td>1</td>
              <td>DataCamp NumPy fundamentals, array operations, broadcasting</td>
              <td>2-3/day</td>
              <td>NumPy basics notebook</td>
            </tr>
            <tr>
              <td>6-10</td>
              <td>2</td>
              <td>Intermediate Python: list comprehensions, functions, modules</td>
              <td>2-3/day</td>
              <td>Python exercises notebook</td>
            </tr>
            <tr>
              <td>11-15</td>
              <td>3</td>
              <td>Data Visualization: matplotlib, seaborn basics</td>
              <td>2-3/day</td>
              <td>Visualization portfolio</td>
            </tr>
            <tr>
              <td>16-20</td>
              <td>4</td>
              <td>Statistics fundamentals: distributions, hypothesis testing</td>
              <td>2-3/day</td>
              <td>Statistics exercises</td>
            </tr>
            <tr>
              <td>21-25</td>
              <td>5</td>
              <td>Linear algebra: vectors, matrices, eigenvalues; Manual gradients</td>
              <td>2-3/day</td>
              <td>Linear algebra notebook</td>
            </tr>
            <tr>
              <td>26-30</td>
              <td>6</td>
              <td>Review week: Quiz (‚â•16/20), Linear regression from scratch (R¬≤&gt;0.90), PCA implementation</td>
              <td>3-4/day</td>
              <td>foundations_summary.md (‚â•5 pages)</td>
            </tr>
          </tbody>
        </table>
      </div>

      <!-- Phase 2: Week 7 Buffer -->
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">Phase 2: Week 7 ‚Äî Buffer & Structure Setup</h3>
        </div>
        <table>
          <thead>
            <tr>
              <th>Day</th>
              <th>Week</th>
              <th>Tasks</th>
              <th>Time (hrs)</th>
              <th>Deliverables</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>31-32</td>
              <td>7</td>
              <td>Setup pytest + black, configure pre-commit hooks</td>
              <td>2</td>
              <td>Test setup validated</td>
            </tr>
            <tr>
              <td>33-34</td>
              <td>7</td>
              <td>Migrate notebooks to Deepnote, organize structure</td>
              <td>2</td>
              <td>Deepnote workspace ready</td>
            </tr>
            <tr>
              <td>35-37</td>
              <td>7</td>
              <td>Create weekly log template, write Week 1-6 retrospective</td>
              <td>1-2/day</td>
              <td>week_07.md log</td>
            </tr>
          </tbody>
        </table>
      </div>

      <!-- Phase 3: Weeks 8-10 Classical ML -->
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">Phase 3: Weeks 8-10 ‚Äî Classical Machine Learning</h3>
        </div>
        <table>
          <thead>
            <tr>
              <th>Day</th>
              <th>Week</th>
              <th>Tasks</th>
              <th>Time (hrs)</th>
              <th>Deliverables</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>38-40</td>
              <td>8</td>
              <td>Sklearn basics: LinearRegression, LogisticRegression, pipelines</td>
              <td>2-3/day</td>
              <td>Classification/regression notebooks</td>
            </tr>
            <tr>
              <td>41-44</td>
              <td>8-9</td>
              <td>Metrics deep dive: accuracy, precision, recall, F1, ROC-AUC, confusion matrices</td>
              <td>2-3/day</td>
              <td>Metrics comparison notebook</td>
            </tr>
            <tr>
              <td>45-47</td>
              <td>9</td>
              <td>Cross-validation: k-fold, stratified, time-series splits</td>
              <td>2-3/day</td>
              <td>CV implementation</td>
            </tr>
            <tr>
              <td>48-51</td>
              <td>9-10</td>
              <td>Learning curves: diagnose underfitting/overfitting</td>
              <td>2-3/day</td>
              <td>Learning curve analysis</td>
            </tr>
            <tr>
              <td>52-56</td>
              <td>10</td>
              <td>MNIST with sklearn (‚â•85% accuracy), hyperparameter tuning</td>
              <td>2-3/day</td>
              <td>classical_ml_report.md</td>
            </tr>
          </tbody>
        </table>
      </div>

      <!-- Phase 4: Weeks 11-17 Deep Learning Core -->
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">Phase 4: Weeks 11-17 ‚Äî Deep Learning Core</h3>
        </div>
        <table>
          <thead>
            <tr>
              <th>Day</th>
              <th>Week</th>
              <th>Tasks</th>
              <th>Time (hrs)</th>
              <th>Deliverables</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>57-63</td>
              <td>11</td>
              <td>PyTorch basics: tensors, autograd, nn.Module; Read "How to Read a Paper"</td>
              <td>2-3/day</td>
              <td>PyTorch fundamentals notebook</td>
            </tr>
            <tr>
              <td>64-70</td>
              <td>12</td>
              <td>Build MLP for MNIST (‚â•97% accuracy)</td>
              <td>2-3/day</td>
              <td>MLP implementation + logs</td>
            </tr>
            <tr>
              <td>71-77</td>
              <td>13</td>
              <td>CNN architecture: convolution, pooling, stride/padding</td>
              <td>2-3/day</td>
              <td>CNN layer notebooks</td>
            </tr>
            <tr>
              <td>78-84</td>
              <td>14</td>
              <td>Training stability: learning rate scheduling, gradient clipping, normalization (BatchNorm, LayerNorm)</td>
              <td>2-3/day</td>
              <td>Stability experiments</td>
            </tr>
            <tr>
              <td>85-91</td>
              <td>15</td>
              <td>Activation/gradient visualization: hooks, tensorboard</td>
              <td>2-3/day</td>
              <td>Visualization tools</td>
            </tr>
            <tr>
              <td>92-98</td>
              <td>16</td>
              <td>CIFAR-10 CNN sprint on Kaggle GPU (‚â•70% accuracy)</td>
              <td>3-4/day</td>
              <td>CIFAR-10 model + logs</td>
            </tr>
            <tr>
              <td>99-105</td>
              <td>17</td>
              <td>Review: mixed precision (fp16), data augmentation</td>
              <td>2-3/day</td>
              <td>deep_learning_health_check.md</td>
            </tr>
          </tbody>
        </table>
      </div>

      <!-- Phase 5: Week 18 Buffer -->
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">Phase 5: Week 18 ‚Äî Buffer & NLP Warmup</h3>
        </div>
        <table>
          <thead>
            <tr>
              <th>Day</th>
              <th>Week</th>
              <th>Tasks</th>
              <th>Time (hrs)</th>
              <th>Deliverables</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>106-108</td>
              <td>18</td>
              <td>Character-level dataset preparation (Shakespeare, WikiText)</td>
              <td>2</td>
              <td>Char dataset ready</td>
            </tr>
            <tr>
              <td>109-112</td>
              <td>18</td>
              <td>Optional: Tiny RNN/LSTM experiment for sequence modeling</td>
              <td>1-2/day</td>
              <td>RNN baseline notebook</td>
            </tr>
          </tbody>
        </table>
      </div>

      <!-- Phase 6: Weeks 19-22 Transformer Fundamentals -->
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">Phase 6: Weeks 19-22 ‚Äî Transformer Fundamentals</h3>
        </div>
        <table>
          <thead>
            <tr>
              <th>Day</th>
              <th>Week</th>
              <th>Tasks</th>
              <th>Time (hrs)</th>
              <th>Deliverables</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>113-119</td>
              <td>19</td>
              <td>Read "Attention Is All You Need" (3-pass); Implement scaled dot-product attention</td>
              <td>2-3/day</td>
              <td>Paper notes + attention.py</td>
            </tr>
            <tr>
              <td>120-126</td>
              <td>20</td>
              <td>Multi-Head Attention (MHA) from scratch with unit tests</td>
              <td>2-3/day</td>
              <td>MHA implementation + tests</td>
            </tr>
            <tr>
              <td>127-133</td>
              <td>21</td>
              <td>Positional encoding: sinusoidal, learned; Read BERT paper</td>
              <td>2-3/day</td>
              <td>Positional encoding variants</td>
            </tr>
            <tr>
              <td>134-140</td>
              <td>22</td>
              <td>Pre-LN Transformer blocks, causal masking, attention heatmaps</td>
              <td>2-3/day</td>
              <td>transformer_fundamentals_summary.md</td>
            </tr>
          </tbody>
        </table>
      </div>

      <!-- Phase 7: Weeks 23-28 GPT from Scratch -->
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">Phase 7: Weeks 23-28 ‚Äî GPT from Scratch (Character-level)</h3>
        </div>
        <table>
          <thead>
            <tr>
              <th>Day</th>
              <th>Week</th>
              <th>Tasks</th>
              <th>Time (hrs)</th>
              <th>Deliverables</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>141-147</td>
              <td>23</td>
              <td>Full GPT training loop: gradient accumulation, mixed precision (amp); Start Colab Pro ($10/month)</td>
              <td>3-4/day</td>
              <td>Training loop + checkpointing</td>
            </tr>
            <tr>
              <td>148-154</td>
              <td>24</td>
              <td>Sampling strategies: greedy, temperature, top-k, top-p, repetition penalty</td>
              <td>2-3/day</td>
              <td>Sampling implementations</td>
            </tr>
            <tr>
              <td>155-161</td>
              <td>25</td>
              <td>Train 5M-10M param models on char data; Read GPT-2 paper</td>
              <td>3-4/day</td>
              <td>Small GPT checkpoints</td>
            </tr>
            <tr>
              <td>162-168</td>
              <td>26</td>
              <td><strong>BAGRUT BUFFER:</strong> Maintenance mode (15-30 min/day), paper reading only</td>
              <td>0.5/day</td>
              <td>Light progress log</td>
            </tr>
            <tr>
              <td>169-175</td>
              <td>27</td>
              <td><strong>BAGRUT BUFFER:</strong> Maintenance mode continues; Read GPT-3 paper</td>
              <td>0.5/day</td>
              <td>GPT-3 paper notes</td>
            </tr>
            <tr>
              <td>176-182</td>
              <td>28</td>
              <td><strong>BAGRUT BUFFER:</strong> Light refactoring, resume training; Scale to 15-20M params</td>
              <td>1-2/day</td>
              <td>scaling_report_v1.md</td>
            </tr>
          </tbody>
        </table>
      </div>

      <!-- Phase 8: Weeks 29-33 Tokenizer + Scaling -->
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">Phase 8: Weeks 29-33 ‚Äî BPE Tokenizer + Data Curation + Scaling Laws</h3>
        </div>
        <table>
          <thead>
            <tr>
              <th>Day</th>
              <th>Week</th>
              <th>Tasks</th>
              <th>Time (hrs)</th>
              <th>Deliverables</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>183-189</td>
              <td>29</td>
              <td>Train BPE tokenizer (16k vocab) on curated corpus</td>
              <td>2-3/day</td>
              <td>BPE tokenizer.pkl</td>
            </tr>
            <tr>
              <td>190-196</td>
              <td>30</td>
              <td>Data curation: normalize, deduplicate, filter corpus</td>
              <td>2-3/day</td>
              <td>dataset_report.md</td>
            </tr>
            <tr>
              <td>197-203</td>
              <td>31</td>
              <td>Scaling experiments: 1M/3M/10M parameter models; Read Chinchilla paper</td>
              <td>3-4/day</td>
              <td>Scaling curves (compute vs loss)</td>
            </tr>
            <tr>
              <td>204-210</td>
              <td>32</td>
              <td>Continue scaling: 20M/30M models; Track GPU usage in gpu_log.md</td>
              <td>3-4/day</td>
              <td>Extended scaling curves</td>
            </tr>
            <tr>
              <td>211-217</td>
              <td>33</td>
              <td>Character vs BPE comparison; End Colab Pro subscription</td>
              <td>2-3/day</td>
              <td>tokenizer_data_scaling_summary.md</td>
            </tr>
          </tbody>
        </table>
      </div>

      <!-- Phase 9: Weeks 34-36 MVP Serving -->
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">Phase 9: Weeks 34-36 ‚Äî Ethics/Safety + MVP Serving</h3>
        </div>
        <table>
          <thead>
            <tr>
              <th>Day</th>
              <th>Week</th>
              <th>Tasks</th>
              <th>Time (hrs)</th>
              <th>Deliverables</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>218-221</td>
              <td>34</td>
              <td>Write safety.md; Design content filtering.py (keywords, regex)</td>
              <td>2-3/day</td>
              <td>safety.md + filtering.py</td>
            </tr>
            <tr>
              <td>222-224</td>
              <td>34</td>
              <td>Red-team with 100 prompts; Measure false positives/negatives</td>
              <td>2/day</td>
              <td>Red team report</td>
            </tr>
            <tr>
              <td>225-231</td>
              <td>35</td>
              <td>FastAPI + Docker setup; FrontendMasters UI guidance</td>
              <td>2-3/day</td>
              <td>API + minimal UI</td>
            </tr>
            <tr>
              <td>232-238</td>
              <td>36</td>
              <td>Deploy to DigitalOcean, HTTPS setup, Sentry monitoring</td>
              <td>2-3/day</td>
              <td>deployment_mvp_report.md + live URL</td>
            </tr>
          </tbody>
        </table>
      </div>

      <!-- Phase 10: Weeks 37-40 PEFT/QLoRA -->
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">Phase 10: Weeks 37-40 ‚Äî PEFT/QLoRA + Inference Optimization</h3>
        </div>
        <table>
          <thead>
            <tr>
              <th>Day</th>
              <th>Week</th>
              <th>Tasks</th>
              <th>Time (hrs)</th>
              <th>Deliverables</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>239-245</td>
              <td>37</td>
              <td>Read LoRA paper; Implement LoRA adapter layers</td>
              <td>2-3/day</td>
              <td>LoRA implementation</td>
            </tr>
            <tr>
              <td>246-252</td>
              <td>38</td>
              <td>Fine-tune 3B-7B model with LoRA/QLoRA on Azure ($40-60 budget)</td>
              <td>3-4/day</td>
              <td>Fine-tuned checkpoints</td>
            </tr>
            <tr>
              <td>253-259</td>
              <td>39</td>
              <td>Quantization: 8-bit and 4-bit (bitsandbytes); Read FlashAttention paper</td>
              <td>2-3/day</td>
              <td>Quantized models</td>
            </tr>
            <tr>
              <td>260-266</td>
              <td>40</td>
              <td>KV-cache implementation; Measure latency improvements (‚â•30%)</td>
              <td>2-3/day</td>
              <td>peft_inference_summary.md</td>
            </tr>
          </tbody>
        </table>
      </div>

      <!-- Phase 11: Week 41 Buffer -->
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">Phase 11: Week 41 ‚Äî Buffer & Cleanup</h3>
        </div>
        <table>
          <thead>
            <tr>
              <th>Day</th>
              <th>Week</th>
              <th>Tasks</th>
              <th>Time (hrs)</th>
              <th>Deliverables</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>267-270</td>
              <td>41</td>
              <td>Code refactoring: modularize training/inference code</td>
              <td>2/day</td>
              <td>Cleaner codebase</td>
            </tr>
            <tr>
              <td>271-273</td>
              <td>41</td>
              <td>Write unit tests for tokenizer and sampling functions</td>
              <td>2/day</td>
              <td>Test coverage report</td>
            </tr>
          </tbody>
        </table>
      </div>

      <!-- Phase 12: Weeks 42-44 MLOps -->
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">Phase 12: Weeks 42-44 ‚Äî MLOps Essentials</h3>
        </div>
        <table>
          <thead>
            <tr>
              <th>Day</th>
              <th>Week</th>
              <th>Tasks</th>
              <th>Time (hrs)</th>
              <th>Deliverables</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>274-280</td>
              <td>42</td>
              <td>Pytest suite for all critical functions; Black formatter setup</td>
              <td>2-3/day</td>
              <td>Comprehensive test suite</td>
            </tr>
            <tr>
              <td>281-287</td>
              <td>43</td>
              <td>GitHub Actions CI: run tests + format checks on push</td>
              <td>2-3/day</td>
              <td>CI pipeline active</td>
            </tr>
            <tr>
              <td>288-294</td>
              <td>44</td>
              <td>YAML configs for hyperparams; JSONL logging; Cleanup scripts</td>
              <td>2-3/day</td>
              <td>Config system + logs</td>
            </tr>
          </tbody>
        </table>
      </div>

      <!-- Phase 13: Weeks 45-48 Capstone -->
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">Phase 13: Weeks 45-48 ‚Äî Capstone Project</h3>
        </div>
        <table>
          <thead>
            <tr>
              <th>Day</th>
              <th>Week</th>
              <th>Tasks</th>
              <th>Time (hrs)</th>
              <th>Deliverables</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>295-301</td>
              <td>45</td>
              <td>Choose capstone (Math Assistant OR Hebrew-English Code Assistant); Requirements doc</td>
              <td>2-3/day</td>
              <td>Capstone spec</td>
            </tr>
            <tr>
              <td>302-308</td>
              <td>46</td>
              <td>Data collection: 500-1000 Q&A pairs or coding tasks</td>
              <td>3-4/day</td>
              <td>Capstone dataset</td>
            </tr>
            <tr>
              <td>309-315</td>
              <td>47</td>
              <td>Model training/fine-tuning (10-25M params)</td>
              <td>3-4/day</td>
              <td>Capstone model checkpoint</td>
            </tr>
            <tr>
              <td>316-322</td>
              <td>48</td>
              <td>Evaluation on 100 test cases (‚â•60% correct, ‚â•3.5/5 quality)</td>
              <td>2-3/day</td>
              <td>Capstone evaluation report</td>
            </tr>
          </tbody>
        </table>
      </div>

      <!-- Phase 14: Weeks 49-52 Portfolio -->
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">Phase 14: Weeks 49-52 ‚Äî Portfolio & Final Polish</h3>
        </div>
        <table>
          <thead>
            <tr>
              <th>Day</th>
              <th>Week</th>
              <th>Tasks</th>
              <th>Time (hrs)</th>
              <th>Deliverables</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>323-329</td>
              <td>49</td>
              <td>Write bilingual blog post #1 (Hebrew): Scaling lessons learned</td>
              <td>2-3/day</td>
              <td>Hebrew blog post</td>
            </tr>
            <tr>
              <td>330-336</td>
              <td>50</td>
              <td>Write bilingual blog post #2 (English): BPE tokenizer pitfalls</td>
              <td>2-3/day</td>
              <td>English blog post #1</td>
            </tr>
            <tr>
              <td>337-343</td>
              <td>51</td>
              <td>Write blog post #3 (English): MVP shipping process; Create architecture diagrams</td>
              <td>2-3/day</td>
              <td>English blog post #2 + diagrams</td>
            </tr>
            <tr>
              <td>344-350</td>
              <td>52</td>
              <td>Final portfolio polish: READMEs, documentation, public demos</td>
              <td>2-3/day</td>
              <td>master_summary.txt</td>
            </tr>
          </tbody>
        </table>
      </div>

      <div class="callout callout-success">
        <div class="callout-title">‚úÖ Daily Breakdown Summary</div>
        <p><strong>Total program duration:</strong> 52 weeks (350 days)</p>
        <p><strong>Average time commitment:</strong> 2-3 hours per day, with 3-4 hours during intensive phases</p>
        <p><strong>Buffer periods:</strong> Weeks 7, 18, 26-28 (Bagrut), 41</p>
        <p><strong>Review gates:</strong> After Weeks 6, 10, 17, 22, 28, 33, 36, 40, 44, 48</p>
      </div>
    </section>
    
    <!-- 6. Israeli Context Integration -->
    <section id="israeli-context" class="content-section">
    <!-- 6. Israeli Context Integration -->
    <section id="israeli-context" class="content-section">
      <div class="section-header">
        <h2>6. Israeli Context Integration</h2>
        <button class="anchor-link" aria-label="Copy link to this section" title="Copy link">#</button>
      </div>
      <div class="card-grid">
        <div class="card">
          <h3 class="card-title">üìö Bagrut Buffers</h3>
          <p><strong>Weeks 26‚Äì28:</strong> Maintenance mode</p>
          <ul>
            <li>15‚Äì30 minutes per day</li>
            <li>Focus: paper reading, logs, light refactoring</li>
            <li>No new implementation during exam period</li>
          </ul>
        </div>
        <div class="card">
          <h3 class="card-title">üéñÔ∏è IDF Positioning</h3>
          <p><strong>Target completion:</strong> Week 40</p>
          <ul>
            <li>Security/privacy focus in projects</li>
            <li>Systems thinking demonstrations</li>
            <li>Prepare portfolio presentation</li>
          </ul>
        </div>
        <div class="card">
          <h3 class="card-title">üéì University Programs</h3>
          <p><strong>Application prep:</strong> Week 44</p>
          <ul>
            <li>HUJI "Mahar" program</li>
            <li>TAU "Alpha" program</li>
            <li>Portfolio and achievements documentation</li>
          </ul>
        </div>
        <div class="card">
          <h3 class="card-title">üåê Community & Language</h3>
          <p><strong>Target:</strong> By Week 52</p>
          <ul>
            <li>PyData TLV meetups</li>
            <li>AI Israel community</li>
            <li>3 Hebrew blog posts</li>
            <li>3 English blog posts</li>
          </ul>
        </div>
      </div>
    </section>
    
    <!-- 7. Optimized GPU Strategy -->
    <section id="gpu-strategy" class="content-section">
      <div class="section-header">
        <h2>7. Optimized GPU Strategy</h2>
        <button class="anchor-link" aria-label="Copy link to this section" title="Copy link">#</button>
      </div>
      <div class="card">
        <h3>Budget Allocation & Priority</h3>
        <table>
          <thead>
            <tr>
              <th>Resource</th>
              <th>Budget</th>
              <th>Usage Window</th>
              <th>Purpose</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>Kaggle (free T4)</td>
              <td>Free</td>
              <td>Default</td>
              <td>Prototypes, CIFAR, many scaling runs</td>
            </tr>
            <tr>
              <td>Colab Pro</td>
              <td>~$10</td>
              <td>ONE month (Weeks 23‚Äì33)</td>
              <td>Pretraining and scaling experiments</td>
            </tr>
            <tr>
              <td>Azure Credit</td>
              <td>$40‚Äì$60</td>
              <td>Weeks 37‚Äì40</td>
              <td>QLoRA fine-tuning</td>
            </tr>
            <tr>
              <td>Azure Buffer</td>
              <td>~$40</td>
              <td>Emergency only</td>
              <td>Critical experiments if blocked</td>
            </tr>
          </tbody>
        </table>
      </div>
      
      <div class="callout callout-warning">
        <div class="callout-title">‚ö° Priority Ladder When GPU Constrained</div>
        <ol>
          <li>Use Kaggle free T4</li>
          <li>Use Colab Free tier</li>
          <li>Shrink model size / context length / batch size</li>
          <li>Reduce training steps</li>
          <li>Focus on documentation and evaluation</li>
          <li>Use Colab Pro (if within budget window)</li>
          <li>Use Azure credit (emergency only)</li>
        </ol>
      </div>
      
      <div class="callout callout-info">
        <div class="callout-title">üìä Tracking Requirement</div>
        <p><strong>Maintain <code>docs/gpu_log.md</code></strong> to track minutes used on each platform, experiment purpose, and costs.</p>
      </div>
    </section>
    
    <!-- 8. Research Paper Reading Protocol -->
    <section id="research" class="content-section">
      <div class="section-header">
        <h2>8. Research Paper Reading Protocol</h2>
        <button class="anchor-link" aria-label="Copy link to this section" title="Copy link">#</button>
      </div>
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">Reading Methodology</h3>
        </div>
        <p><strong>Week 11:</strong> Read Keshav's "How to Read a Paper" (3-pass method)</p>
      </div>
      
      <div class="timeline">
        <div class="timeline-item">
          <h4>Weeks 19‚Äì20: "Attention Is All You Need"</h4>
          <p>3-pass deep read, implement attention from scratch</p>
        </div>
        <div class="timeline-item">
          <h4>Weeks 21‚Äì22: BERT</h4>
          <p>Understand bidirectional training, MLM objective</p>
        </div>
        <div class="timeline-item">
          <h4>Weeks 25‚Äì26: GPT-2</h4>
          <p>Autoregressive pretraining, model architecture details</p>
        </div>
        <div class="timeline-item">
          <h4>Weeks 27‚Äì28: GPT-3</h4>
          <p>Scaling laws, few-shot learning, emergent abilities</p>
        </div>
        <div class="timeline-item">
          <h4>Weeks 31‚Äì32: Chinchilla</h4>
          <p>Compute-optimal training, data vs parameters trade-offs</p>
        </div>
        <div class="timeline-item">
          <h4>Weeks 37‚Äì38: LoRA</h4>
          <p>Low-rank adaptation, parameter-efficient fine-tuning</p>
        </div>
        <div class="timeline-item">
          <h4>Weeks 39‚Äì40: FlashAttention</h4>
          <p>IO-aware attention, memory optimization techniques</p>
        </div>
      </div>
      
      <div class="callout callout-success">
        <div class="callout-title">üìù Note-Taking</div>
        <p>Store notes per paper in Notion with:</p>
        <ul>
          <li>Key contributions and insights</li>
          <li>Implementation details</li>
          <li>Questions and unclear points</li>
          <li>Connections to other papers</li>
        </ul>
      </div>
    </section>
    
    <!-- 9. Community & Mentorship Structure -->
    <section id="community" class="content-section">
      <div class="section-header">
        <h2>9. Community & Mentorship Structure</h2>
        <button class="anchor-link" aria-label="Copy link to this section" title="Copy link">#</button>
      </div>
      
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">üöÄ Immediate Actions</h3>
        </div>
        <ul>
          <li>Join Hugging Face Discord</li>
          <li>Join EleutherAI Discord</li>
          <li>Subscribe to r/LocalLLaMA</li>
          <li>Follow key voices:
            <ul>
              <li>@karpathy (Andrej Karpathy)</li>
              <li>@srush_nlp (Sasha Rush)</li>
              <li>@ykilcher (Yannic Kilcher)</li>
            </ul>
          </li>
        </ul>
      </div>
      
      <div class="card-grid">
        <div class="card">
          <h3 class="card-title">üìÖ Weekly (from Week 4)</h3>
          <ul>
            <li>Post one progress update</li>
            <li>Ask one thoughtful question</li>
            <li>Answer one community question</li>
          </ul>
        </div>
        <div class="card">
          <h3 class="card-title">üóìÔ∏è Monthly (from Week 8)</h3>
          <ul>
            <li>Connect with study partner</li>
            <li>Schedule mentor call by Week 12</li>
            <li>Review progress and adjust plan</li>
          </ul>
        </div>
        <div class="card">
          <h3 class="card-title">üìä Quarterly</h3>
          <ul>
            <li>Present work to community</li>
            <li>Gather feedback on projects</li>
            <li>Update portfolio publicly</li>
          </ul>
        </div>
      </div>
    </section>
    
    <!-- 10. Success Criteria (Phase Gates) -->
    <section id="success-criteria" class="content-section">
      <div class="section-header">
        <h2>10. Success Criteria (Phase Gates)</h2>
        <button class="anchor-link" aria-label="Copy link to this section" title="Copy link">#</button>
      </div>
      
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">üìê Foundations (Week 6)</h3>
        </div>
        <ul>
          <li>Quiz score ‚â•16/20</li>
          <li>Linear regression (NumPy only) with R¬≤&gt;0.90</li>
          <li>PCA implementation from scratch</li>
          <li>Explain backprop basics clearly</li>
        </ul>
      </div>
      
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">ü§ñ Classical ML (Week 10)</h3>
        </div>
        <ul>
          <li>MNIST classification ‚â•85% accuracy (sklearn)</li>
          <li>Demonstrate proper learning curves</li>
          <li>Cross-validation implementation</li>
        </ul>
      </div>
      
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">üß† Deep Learning (Week 17)</h3>
        </div>
        <ul>
          <li>MLP on MNIST ‚â•97% accuracy</li>
          <li>CIFAR-10 CNN ‚â•70% accuracy</li>
          <li>Logs include: loss, accuracy, learning rate, gradient norms</li>
          <li>No NaN losses during training</li>
        </ul>
      </div>
      
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">üîÑ Transformers (Week 22)</h3>
        </div>
        <ul>
          <li>Custom attention matches PyTorch MHA on small tests</li>
          <li>Causal masking implemented correctly</li>
          <li>Explain sqrt(d_k) scaling clearly</li>
        </ul>
      </div>
      
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">üöÄ GPT Implementation (Week 28)</h3>
        </div>
        <ul>
          <li>Smooth loss curve for ‚â•10k steps</li>
          <li>Validation perplexity &lt; 2√ó training perplexity</li>
          <li>All sampling strategies work correctly</li>
          <li>Checkpoint save/resume tested</li>
        </ul>
      </div>
      
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">üî§ Tokenizer & Scaling (Week 33)</h3>
        </div>
        <ul>
          <li>BPE tokenizer with 16k vocabulary trained</li>
          <li>Character vs BPE comparison documented</li>
          <li>‚â•5 model sizes with loss vs compute curves</li>
        </ul>
      </div>
      
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">üåê Serving & Safety (Week 36)</h3>
        </div>
        <ul>
          <li>p95 first-token latency &lt;450ms</li>
          <li>Handle ‚â•10 requests/min</li>
          <li>Safety filter: FN&lt;2%, FP&lt;5%</li>
          <li>HTTPS endpoint live and accessible</li>
        </ul>
      </div>
      
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">‚ö° PEFT & Optimization (Week 40)</h3>
        </div>
        <ul>
          <li>LoRA/QLoRA improves task performance</li>
          <li>Quantization saves ‚â•40% memory with &lt;10% quality loss</li>
          <li>KV-cache reduces latency ‚â•30%</li>
        </ul>
      </div>
      
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">üéØ Capstone (Week 48)</h3>
        </div>
        <ul>
          <li>Meets option-specific metrics (see Weekly Plan)</li>
          <li>Reliable demo that doesn't crash</li>
          <li>Proper repository documentation</li>
        </ul>
      </div>
    </section>
    
    <!-- 11. Failure Scenarios & Recovery Protocols -->
    <section id="failure-recovery" class="content-section">
      <div class="section-header">
        <h2>11. Failure Scenarios & Recovery Protocols</h2>
        <button class="anchor-link" aria-label="Copy link to this section" title="Copy link">#</button>
      </div>
      
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">üî• Training Instability</h3>
        </div>
        <p><strong>Symptoms:</strong> Loss spikes, NaN values, exploding gradients</p>
        <p><strong>Recovery steps:</strong></p>
        <ol>
          <li>Lower learning rate by 10√ó</li>
          <li>Enable gradient clipping (max_norm=1.0)</li>
          <li>Check normalization layers (LayerNorm positions)</li>
          <li>Switch to AdamW with warmup</li>
          <li>Inspect input data for anomalies</li>
          <li>Adjust mixed precision settings (try fp32 for debugging)</li>
          <li>Post minimal reproducible example (MRE) in community</li>
        </ol>
      </div>
      
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">‚ùå Model Not Learning</h3>
        </div>
        <p><strong>Symptoms:</strong> Loss doesn't decrease, validation = random</p>
        <p><strong>Recovery steps:</strong></p>
        <ol>
          <li>Assert all tensor shapes explicitly</li>
          <li>Sample and inspect model outputs frequently</li>
          <li>Verify causal mask is applied correctly</li>
          <li>Spot-check loss calculation manually</li>
          <li>Confirm gradients are flowing (use hooks)</li>
          <li>Try tiny model + tiny dataset (overfit test)</li>
          <li>Compare implementation to nanoGPT or minGPT</li>
        </ol>
      </div>
      
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">üíª GPU Exhausted</h3>
        </div>
        <p><strong>Symptoms:</strong> Out of credits or quota limits</p>
        <p><strong>Recovery steps:</strong></p>
        <ol>
          <li>Follow GPU priority ladder (see GPU Strategy section)</li>
          <li>Continue documentation and evaluation work if training paused</li>
          <li>Log all usage in <code>docs/gpu_log.md</code></li>
          <li>Wait for quota resets (Kaggle: weekly, Colab: varies)</li>
        </ol>
      </div>
      
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">üìö Exams / Illness</h3>
        </div>
        <p><strong>Triggers:</strong> Bagrut exams, sick days, emergencies</p>
        <p><strong>Maintenance mode protocol:</strong></p>
        <ul>
          <li>Reduce to 15‚Äì30 minutes per day</li>
          <li>Focus on: reading papers, updating logs, light refactoring</li>
          <li>No new implementations during this period</li>
          <li>Resume full schedule when recovered</li>
        </ul>
      </div>
      
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">üò∞ Burnout</h3>
        </div>
        <p><strong>Symptoms:</strong> Dread, procrastination, exhaustion, loss of interest</p>
        <p><strong>Recovery protocol:</strong></p>
        <ol>
          <li>Take 3 full days off (complete break)</li>
          <li>Do a fun mini-project (game, art, anything unrelated)</li>
          <li>Review list of wins and progress made</li>
          <li>Reduce weekly load by 25‚Äì50%</li>
          <li>Add buffer weeks to schedule</li>
          <li>Tell mentor and/or study partner</li>
          <li>Consider professional help if symptoms persist</li>
        </ol>
      </div>
      
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">ü§î Concept Doesn't Click</h3>
        </div>
        <p><strong>Symptoms:</strong> Stuck on concept for multiple days</p>
        <p><strong>Recovery steps:</strong></p>
        <ol>
          <li>Find 3 different explanations (blog, video, paper)</li>
          <li>Implement the simplest possible version</li>
          <li>Draw diagrams and visualizations</li>
          <li>Ask specific question with MRE in community</li>
          <li>Park the concept and revisit in 1‚Äì2 weeks</li>
        </ol>
      </div>
    </section>
    
    <!-- 12. MLOps Essentials (Simplified) -->
    <section id="mlops" class="content-section">
      <div class="section-header">
        <h2>12. MLOps Essentials (Simplified)</h2>
        <button class="anchor-link" aria-label="Copy link to this section" title="Copy link">#</button>
      </div>
      
      <div class="callout callout-info">
        <div class="callout-title">üéØ Focus: Essential Tools Only</div>
        <p>Streamlined to core practices. Optional tooling clearly marked.</p>
      </div>
      
      <div class="card-grid">
        <div class="card">
          <h3 class="card-title">‚úÖ Testing</h3>
          <ul>
            <li><strong>Pytest</strong> for unit tests</li>
            <li>Test critical functions: tokenizer, attention, sampling</li>
            <li>Integration tests for training loops</li>
          </ul>
        </div>
        <div class="card">
          <h3 class="card-title">üé® Code Quality</h3>
          <ul>
            <li><strong>Black</strong> for formatting</li>
            <li>Pre-commit hooks (optional)</li>
            <li>Consistent style across codebase</li>
          </ul>
        </div>
        <div class="card">
          <h3 class="card-title">üîÑ CI/CD</h3>
          <ul>
            <li><strong>GitHub Actions</strong> for CI</li>
            <li>Run tests on push</li>
            <li>Format checks</li>
          </ul>
        </div>
        <div class="card">
          <h3 class="card-title">‚öôÔ∏è Configuration</h3>
          <ul>
            <li>Simple <strong>YAML files</strong> for hyperparameters</li>
            <li>No complex framework required</li>
            <li>Version control all configs</li>
          </ul>
        </div>
        <div class="card">
          <h3 class="card-title">üìä Logging</h3>
          <ul>
            <li><strong>JSONL format</strong> for experiments</li>
            <li>Track: loss, metrics, hyperparams, timestamps</li>
            <li>Easy to parse and analyze</li>
          </ul>
        </div>
        <div class="card">
          <h3 class="card-title">üßπ Cleanup</h3>
          <ul>
            <li>Scripts to delete old checkpoints</li>
            <li>Keep only best/recent checkpoints</li>
            <li>Manage disk space proactively</li>
          </ul>
        </div>
      </div>
      
      <div class="callout callout-warning">
        <div class="callout-title">‚ö° Optional Tools</div>
        <ul>
          <li><strong>torch.profiler:</strong> For performance bottleneck analysis</li>
          <li><strong>torch.compile:</strong> For inference speedup (PyTorch 2.0+)</li>
          <li>Use only if time permits and clear benefit</li>
        </ul>
      </div>
    </section>
    
    <!-- 13. Removed/Changed Items -->
    <section id="changes" class="content-section">
      <div class="section-header">
        <h2>13. Removed/Changed Items</h2>
        <button class="anchor-link" aria-label="Copy link to this section" title="Copy link">#</button>
      </div>
      
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">‚ùå Removed from Plan</h3>
        </div>
        <ul>
          <li><strong>RAG (Retrieval-Augmented Generation):</strong> Removed from core path, stretch goal only</li>
          <li><strong>Multiple tokenizer sizes:</strong> Single BPE with 16k vocabulary (simplified)</li>
          <li><strong>DVC (Data Version Control):</strong> Removed by default, not essential for learning</li>
          <li><strong>Bandit security scanner:</strong> Removed by default</li>
          <li><strong>Mypy type checking:</strong> Removed by default</li>
          <li><strong>GitHub certification:</strong> Not required</li>
        </ul>
      </div>
      
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">üìù Simplified Items</h3>
        </div>
        <ul>
          <li><strong>MLOps:</strong> Reduced to essentials only (pytest, black, CI, YAML, JSONL)</li>
          <li><strong>torch.compile:</strong> Now optional</li>
          <li><strong>Multiple BPE experiments:</strong> Focus on one working implementation</li>
        </ul>
      </div>
      
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">üîÑ What Changed from v3</h3>
        </div>
        <ul>
          <li>Robotics and control systems completely removed</li>
          <li>Pure LLM focus from start to finish</li>
          <li>GPU strategy optimized with clear budget allocation</li>
          <li>Israeli context (Bagrut, IDF, university) explicitly integrated</li>
          <li>Clearer buffer weeks and review gates</li>
          <li>More realistic timelines based on prior feedback</li>
        </ul>
      </div>
    </section>
    
    <!-- 14. Repo Structure -->
    <section id="repo-structure" class="content-section">
      <div class="section-header">
        <h2>14. Repository Structure</h2>
        <button class="anchor-link" aria-label="Copy link to this section" title="Copy link">#</button>
      </div>
      
      <div class="code-block">
        <div class="code-block-header">
          <span>Updated Repository Tree</span>
        </div>
        <pre><code>llm-mastery-plan/
‚îú‚îÄ‚îÄ README.md                      # Main project overview
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îî‚îÄ‚îÄ ci.yml                 # GitHub Actions CI pipeline
‚îú‚îÄ‚îÄ requirements.txt               # Python dependencies
‚îú‚îÄ‚îÄ setup.py                       # Package setup (optional)
‚îÇ
‚îú‚îÄ‚îÄ docs/                          # All documentation
‚îÇ   ‚îú‚îÄ‚îÄ foundations_summary.md
‚îÇ   ‚îú‚îÄ‚îÄ classical_ml_report.md
‚îÇ   ‚îú‚îÄ‚îÄ deep_learning_health_check.md
‚îÇ   ‚îú‚îÄ‚îÄ transformer_fundamentals_summary.md
‚îÇ   ‚îú‚îÄ‚îÄ scaling_report_v1.md
‚îÇ   ‚îú‚îÄ‚îÄ tokenizer_data_scaling_summary.md
‚îÇ   ‚îú‚îÄ‚îÄ deployment_mvp_report.md
‚îÇ   ‚îú‚îÄ‚îÄ peft_inference_summary.md
‚îÇ   ‚îú‚îÄ‚îÄ master_summary.txt
‚îÇ   ‚îú‚îÄ‚îÄ dataset_report.md
‚îÇ   ‚îú‚îÄ‚îÄ safety.md
‚îÇ   ‚îú‚îÄ‚îÄ gpu_log.md                # Track GPU usage
‚îÇ   ‚îú‚îÄ‚îÄ weekly_logs/              # Weekly progress logs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ week_01.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ week_02.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ papers/                   # Paper notes
‚îÇ       ‚îú‚îÄ‚îÄ attention_is_all_you_need.md
‚îÇ       ‚îú‚îÄ‚îÄ bert.md
‚îÇ       ‚îú‚îÄ‚îÄ gpt2.md
‚îÇ       ‚îú‚îÄ‚îÄ gpt3.md
‚îÇ       ‚îú‚îÄ‚îÄ chinchilla.md
‚îÇ       ‚îú‚îÄ‚îÄ lora.md
‚îÇ       ‚îî‚îÄ‚îÄ flash_attention.md
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                     # Jupyter/Deepnote notebooks
‚îÇ   ‚îú‚îÄ‚îÄ foundations/
‚îÇ   ‚îú‚îÄ‚îÄ classical_ml/
‚îÇ   ‚îú‚îÄ‚îÄ deep_learning/
‚îÇ   ‚îú‚îÄ‚îÄ transformers/
‚îÇ   ‚îî‚îÄ‚îÄ experiments/
‚îÇ
‚îú‚îÄ‚îÄ src/                          # Source code
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ tokenizer/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bpe.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils.py
‚îÇ   ‚îú‚îÄ‚îÄ model/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ attention.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ transformer.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gpt.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config.py
‚îÇ   ‚îú‚îÄ‚îÄ training/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ trainer.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ loss.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ optimizer.py
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dataset.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ augmentation.py
‚îÇ   ‚îú‚îÄ‚îÄ evaluation/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metrics.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ harness.py
‚îÇ   ‚îú‚îÄ‚îÄ serving/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ inference.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ filtering.py
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ logging.py
‚îÇ       ‚îî‚îÄ‚îÄ checkpoints.py
‚îÇ
‚îú‚îÄ‚îÄ tests/                        # Test suite
‚îÇ   ‚îú‚îÄ‚îÄ test_tokenizer.py
‚îÇ   ‚îú‚îÄ‚îÄ test_attention.py
‚îÇ   ‚îú‚îÄ‚îÄ test_model.py
‚îÇ   ‚îú‚îÄ‚îÄ test_training.py
‚îÇ   ‚îî‚îÄ‚îÄ test_serving.py
‚îÇ
‚îú‚îÄ‚îÄ configs/                      # YAML configuration files
‚îÇ   ‚îú‚îÄ‚îÄ base.yaml
‚îÇ   ‚îú‚îÄ‚îÄ small.yaml
‚îÇ   ‚îú‚îÄ‚îÄ medium.yaml
‚îÇ   ‚îî‚îÄ‚îÄ serving.yaml
‚îÇ
‚îú‚îÄ‚îÄ scripts/                      # Utility scripts
‚îÇ   ‚îú‚îÄ‚îÄ train.py
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py
‚îÇ   ‚îú‚îÄ‚îÄ serve.py
‚îÇ   ‚îú‚îÄ‚îÄ cleanup_checkpoints.py
‚îÇ   ‚îî‚îÄ‚îÄ export_model.py
‚îÇ
‚îú‚îÄ‚îÄ data/                         # Data directory (gitignored)
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îú‚îÄ‚îÄ processed/
‚îÇ   ‚îî‚îÄ‚îÄ tokenized/
‚îÇ
‚îú‚îÄ‚îÄ checkpoints/                  # Model checkpoints (gitignored)
‚îÇ   ‚îú‚îÄ‚îÄ gpt-1m/
‚îÇ   ‚îú‚îÄ‚îÄ gpt-3m/
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îú‚îÄ‚îÄ logs/                         # Experiment logs (gitignored)
‚îÇ   ‚îî‚îÄ‚îÄ experiments.jsonl
‚îÇ
‚îî‚îÄ‚îÄ deployment/                   # Deployment configs
    ‚îú‚îÄ‚îÄ Dockerfile
    ‚îú‚îÄ‚îÄ docker-compose.yml
    ‚îî‚îÄ‚îÄ nginx.conf</code></pre>
      </div>
    </section>
    
    <!-- 15. Immediate Next Actions -->
    <section id="next-actions" class="content-section">
      <div class="section-header">
        <h2>15. Immediate Next Actions (This Week)</h2>
        <button class="anchor-link" aria-label="Copy link to this section" title="Copy link">#</button>
      </div>
      
      <div class="callout callout-success">
        <div class="callout-title">üéØ Week 1 Priorities</div>
        <p>These tasks establish the foundation for the entire plan. Complete within 7 days.</p>
      </div>
      
      <div class="card-grid">
        <div class="card">
          <h3 class="card-title">üìÅ Setup</h3>
          <ul>
            <li>Create <code>docs/</code> directory with all template files</li>
            <li>Initialize <code>docs/gpu_log.md</code></li>
            <li>Create <code>docs/weekly_logs/week_01.md</code></li>
          </ul>
        </div>
        <div class="card">
          <h3 class="card-title">üîê Security</h3>
          <ul>
            <li>Set up 1Password account</li>
            <li>Store all API keys and tokens</li>
            <li>Never commit secrets to git</li>
          </ul>
        </div>
        <div class="card">
          <h3 class="card-title">üë• Community</h3>
          <ul>
            <li>Join Hugging Face Discord</li>
            <li>Join EleutherAI Discord</li>
            <li>Subscribe to r/LocalLLaMA</li>
            <li>Follow @karpathy, @srush_nlp, @ykilcher</li>
          </ul>
        </div>
        <div class="card">
          <h3 class="card-title">üìì Tools</h3>
          <ul>
            <li>Migrate notebooks to Deepnote</li>
            <li>Set up Notion workspace</li>
            <li>Configure VS Code with Copilot Pro</li>
          </ul>
        </div>
        <div class="card">
          <h3 class="card-title">üìö Learning</h3>
          <ul>
            <li>Start DataCamp NumPy course</li>
            <li>Complete first 2‚Äì3 modules</li>
            <li>Practice in Deepnote notebook</li>
          </ul>
        </div>
        <div class="card">
          <h3 class="card-title">‚úçÔ∏è Writing</h3>
          <ul>
            <li>Write weekly log for Week 1</li>
            <li>Publish intro post (blog or community)</li>
            <li>Share plan with mentor/community</li>
          </ul>
        </div>
      </div>
    </section>
    
    <!-- 16. Mindset -->
    <section id="mindset" class="content-section">
      <div class="section-header">
        <h2>16. Mindset</h2>
        <button class="anchor-link" aria-label="Copy link to this section" title="Copy link">#</button>
      </div>
      
      <div class="card">
        <h3 class="text-gradient" style="font-size: 2rem; text-align: center; margin-bottom: 2rem;">Core Principles</h3>
        
        <div class="callout callout-info">
          <div class="callout-title">üéì Depth Over Speed</div>
          <p>Understanding the fundamentals deeply is more valuable than rushing through topics. If you need extra time on a concept, take it. The goal is mastery, not completion.</p>
        </div>
        
        <div class="callout callout-success">
          <div class="callout-title">üë• Community Over Isolation</div>
          <p>Learning in public and engaging with the community accelerates growth. Share your work, ask questions, help others. You'll learn more by teaching and discussing.</p>
        </div>
        
        <div class="callout callout-warning">
          <div class="callout-title">üìà Progress Over Perfection</div>
          <p>Ship working code, even if it's not perfect. Iterate and improve. "Done is better than perfect" ‚Äî you can always refactor later. The key is to keep moving forward.</p>
        </div>
      </div>
      
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">üõ°Ô∏è Burnout Prevention</h3>
        </div>
        <ul>
          <li><strong>During exam periods (Weeks 26‚Äì28):</strong> Switch to maintenance mode
            <ul>
              <li>15‚Äì30 minutes per day maximum</li>
              <li>Light activities: reading, logging, small refactors</li>
              <li>Resume full schedule after exams</li>
            </ul>
          </li>
          <li><strong>Regular breaks:</strong> Take at least one full day off per week</li>
          <li><strong>Variety:</strong> Mix theory, coding, writing, and experiments</li>
          <li><strong>Celebrate wins:</strong> Acknowledge progress, no matter how small</li>
          <li><strong>Ask for help:</strong> Don't struggle alone for more than 2‚Äì3 days</li>
        </ul>
      </div>
      
      <div class="card">
        <div class="card-header">
          <h3 class="card-title">üåü Long-Term Vision</h3>
        </div>
        <p>This 12-month plan is just the beginning. The skills and knowledge you build will compound over years. Stay curious, stay humble, and keep building.</p>
        <p><strong>Remember:</strong> Every expert was once a beginner. Your consistent effort over 12 months will transform you into someone who can contribute meaningfully to the field of AI and LLMs.</p>
      </div>
    </section>
    
  </main>
  
  <!-- Footer -->
  <footer class="footer" role="contentinfo">
    <p>&copy; 2025 DovJNash. AI & Machine Learning Mastery Plan ‚Äî Revision 4 (LLM-Focused)</p>
    <div class="footer-links">
      <a href="https://github.com/DovJNash" target="_blank" rel="noopener">GitHub</a>
      <a href="#direction">Back to Top</a>
    </div>
    <p style="margin-top: 1rem; font-size: 0.75rem; opacity: 0.7;">
      Built with semantic HTML, CSS, and vanilla JavaScript. No build step required.
    </p>
  </footer>
  
  <!-- JavaScript -->
  <script src="/assets/js/main.js"></script>
</body>
</html>
